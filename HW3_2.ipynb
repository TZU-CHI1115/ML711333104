{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12e1131d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c210bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape = (32256, 2410)\n",
      "y.shape = (38,)\n",
      "Total number of images = 2410\n",
      "Total number of persons = 38\n",
      "Image size = 168 x 192\n",
      "Number of images for each person = [64 62 64 64 62 64 64 64 64 64 60 59 60 63 62 63 63 64 64 64 64 64 64 64\n",
      " 64 64 64 64 64 64 64 64 64 64 64 64 64 64]\n",
      "Total number of images = 2410\n"
     ]
    }
   ],
   "source": [
    "D = scipy.io.loadmat('data/allFaces.mat')\n",
    "X = D['faces'] # 32256 x 2410 each column represents an image\n",
    "y = np.ndarray.flatten(D['nfaces'])\n",
    "m = D['m'].item() # 168\n",
    "n = D['n'].item() # 192\n",
    "n_persons = D['person'].item() # 38\n",
    "\n",
    "# print the data information\n",
    "print('X.shape =', X.shape)\n",
    "print('y.shape =', y.shape)\n",
    "print('Total number of images =', X.shape[1])\n",
    "print('Total number of persons =', n_persons)\n",
    "print('Image size =', m, 'x', n)\n",
    "print('Number of images for each person =',y) \n",
    "print('Total number of images =', y.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9349167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每個人的圖片數量：\n",
      "Person  0: 64 images\n",
      "Person  1: 62 images\n",
      "Person  2: 64 images\n",
      "Person  3: 64 images\n",
      "Person  4: 62 images\n",
      "Person  5: 64 images\n",
      "Person  6: 64 images\n",
      "Person  7: 64 images\n",
      "Person  8: 64 images\n",
      "Person  9: 64 images\n",
      "Person 10: 60 images\n",
      "Person 11: 59 images\n",
      "Person 12: 60 images\n",
      "Person 13: 63 images\n",
      "Person 14: 62 images\n",
      "Person 15: 63 images\n",
      "Person 16: 63 images\n",
      "Person 17: 64 images\n",
      "Person 18: 64 images\n",
      "Person 19: 64 images\n",
      "Person 20: 64 images\n",
      "Person 21: 64 images\n",
      "Person 22: 64 images\n",
      "Person 23: 64 images\n",
      "Person 24: 64 images\n",
      "Person 25: 64 images\n",
      "Person 26: 64 images\n",
      "Person 27: 64 images\n",
      "Person 28: 64 images\n",
      "Person 29: 64 images\n",
      "Person 30: 64 images\n",
      "Person 31: 64 images\n",
      "Person 32: 64 images\n",
      "Person 33: 64 images\n",
      "Person 34: 64 images\n",
      "Person 35: 64 images\n",
      "Person 36: 64 images\n",
      "Person 37: 64 images\n"
     ]
    }
   ],
   "source": [
    "# 根據 y 產生 0~37 的 label\n",
    "label_list = []\n",
    "for person_id, count in enumerate(y):  # y 是每人的圖片數\n",
    "    label_list.extend([person_id] * count)\n",
    "y_full = np.array(label_list)  # 長度為 2410\n",
    "\n",
    "unique, counts = np.unique(y_full, return_counts=True)\n",
    "print(\"每個人的圖片數量：\")\n",
    "for label, count in zip(unique, counts):\n",
    "    print(f\"Person {label:2d}: {count} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f97f7956",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.T # 2410 x 32256 each row represents an image\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a45f54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 1687\n",
      "Testing samples: 723\n",
      "Training data shape: (1687, 32256)\n",
      "Testing data shape: (723, 32256)\n",
      "類別數量： 38\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_full, test_size=0.3, stratify=y_full, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {X_train.shape[0]}\")\n",
    "print(f\"Testing samples: {X_test.shape[0]}\")\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Testing data shape: {X_test.shape}\")\n",
    "print(\"類別數量：\", len(np.unique(y_full)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a4c3e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with CV (solver = lbfgs)\n",
      "Best C = [0.0483293 0.0483293 0.0483293 0.0483293 0.0483293 0.0483293 0.0483293\n",
      " 0.0483293 0.0483293 0.0483293 0.0483293 0.0483293 0.0483293 0.0483293\n",
      " 0.0483293 0.0483293 0.0483293 0.0483293 0.0483293 0.0483293 0.0483293\n",
      " 0.0483293 0.0483293 0.0483293 0.0483293 0.0483293 0.0483293 0.0483293\n",
      " 0.0483293 0.0483293 0.0483293 0.0483293 0.0483293 0.0483293 0.0483293\n",
      " 0.0483293 0.0483293 0.0483293]\n",
      "Training Accuracy: 99.70%\n",
      "Testing Accuracy : 96.96%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       0.95      1.00      0.97        19\n",
      "           2       0.95      1.00      0.97        19\n",
      "           3       1.00      1.00      1.00        19\n",
      "           4       1.00      1.00      1.00        19\n",
      "           5       0.90      1.00      0.95        19\n",
      "           6       1.00      1.00      1.00        19\n",
      "           7       0.95      1.00      0.97        19\n",
      "           8       0.95      1.00      0.98        20\n",
      "           9       1.00      0.95      0.97        19\n",
      "          10       1.00      0.94      0.97        18\n",
      "          11       1.00      0.94      0.97        18\n",
      "          12       0.95      1.00      0.97        18\n",
      "          13       1.00      1.00      1.00        19\n",
      "          14       1.00      1.00      1.00        19\n",
      "          15       1.00      1.00      1.00        19\n",
      "          16       1.00      1.00      1.00        19\n",
      "          17       1.00      1.00      1.00        19\n",
      "          18       0.83      1.00      0.90        19\n",
      "          19       1.00      0.90      0.95        20\n",
      "          20       0.94      0.89      0.92        19\n",
      "          21       1.00      0.95      0.97        19\n",
      "          22       1.00      1.00      1.00        19\n",
      "          23       0.95      1.00      0.98        20\n",
      "          24       1.00      0.95      0.97        19\n",
      "          25       1.00      0.89      0.94        19\n",
      "          26       1.00      1.00      1.00        19\n",
      "          27       1.00      0.95      0.97        19\n",
      "          28       1.00      0.75      0.86        20\n",
      "          29       1.00      0.95      0.97        19\n",
      "          30       1.00      1.00      1.00        19\n",
      "          31       0.95      0.95      0.95        19\n",
      "          32       0.90      1.00      0.95        19\n",
      "          33       0.95      0.95      0.95        19\n",
      "          34       1.00      0.89      0.94        19\n",
      "          35       0.83      1.00      0.90        19\n",
      "          36       0.95      1.00      0.97        19\n",
      "          37       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           0.97       723\n",
      "   macro avg       0.97      0.97      0.97       723\n",
      "weighted avg       0.97      0.97      0.97       723\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from HW3_common_utils import run_logistic_regression_cv\n",
    "\n",
    "# 執行 Logistic Regression CV\n",
    "result = run_logistic_regression_cv(\n",
    "    X_train, X_test, y_train, y_test,\n",
    "    solver='lbfgs',\n",
    "    Cs=np.logspace(-5, 5, 20),\n",
    "    cv=5,\n",
    "    tol=1e-6,\n",
    "    max_iter=int(1e6),\n",
    "    verbose=0,\n",
    "    print_report=True\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
