{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86dacc74",
   "metadata": {},
   "source": [
    "#### <strong>Á¨¨‰∏âÊ¨°‰ΩúÂìÅÔºö‰∏âÂÄãÂàÜÈ°ûÂô®ÊñºÂÖ©ÁµÑÂΩ±ÂÉèÁöÑË©ïÊØîÂØ¶È©ó</strong>\n",
    "Â≠∏ËôüÔºö711333104\n",
    "\n",
    "ÂßìÂêçÔºöÊûóÂ≠êÈΩä\n",
    "<hr>\n",
    "\n",
    " <font color=skyblue>‰ΩúÂìÅÁõÆÊ®ô</font>Ôºö\n",
    " <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8b43f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bb95400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6  \\\n",
      "0  0.309917  0.367769  0.417355  0.442149  0.528926  0.607438  0.657025   \n",
      "1  0.454545  0.471074  0.512397  0.557851  0.595041  0.640496  0.681818   \n",
      "2  0.318182  0.400826  0.491736  0.528926  0.586777  0.657025  0.681818   \n",
      "3  0.198347  0.194215  0.194215  0.194215  0.190083  0.190083  0.243802   \n",
      "4  0.500000  0.545455  0.582645  0.623967  0.648760  0.690083  0.694215   \n",
      "\n",
      "          7         8         9  ...      4087      4088      4089      4090  \\\n",
      "0  0.677686  0.690083  0.685950  ...  0.669422  0.652893  0.661157  0.475207   \n",
      "1  0.702479  0.710744  0.702479  ...  0.157025  0.136364  0.148760  0.152893   \n",
      "2  0.685950  0.702479  0.698347  ...  0.132231  0.181818  0.136364  0.128099   \n",
      "3  0.404959  0.483471  0.516529  ...  0.636364  0.657025  0.685950  0.727273   \n",
      "4  0.714876  0.723140  0.731405  ...  0.161157  0.177686  0.173554  0.177686   \n",
      "\n",
      "       4091      4092      4093      4094      4095  target  \n",
      "0  0.132231  0.148760  0.152893  0.161157  0.157025       0  \n",
      "1  0.152893  0.152893  0.152893  0.152893  0.152893       0  \n",
      "2  0.148760  0.144628  0.140496  0.148760  0.152893       0  \n",
      "3  0.743802  0.764463  0.752066  0.752066  0.739669       0  \n",
      "4  0.177686  0.177686  0.177686  0.173554  0.173554       0  \n",
      "\n",
      "[5 rows x 4097 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Columns: 4097 entries, 0 to target\n",
      "dtypes: float64(4096), int64(1)\n",
      "memory usage: 12.5 MB\n",
      "None\n",
      "Index(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
      "       ...\n",
      "       '4087', '4088', '4089', '4090', '4091', '4092', '4093', '4094', '4095',\n",
      "       'target'],\n",
      "      dtype='object', length=4097)\n",
      "Ë≥áÊñôÁ∂≠Â∫¶Ôºö (400, 4097)\n"
     ]
    }
   ],
   "source": [
    "data_file = 'Data/face_data.csv'\n",
    "df = pd.read_csv(data_file)\n",
    "\n",
    "# È°ØÁ§∫ÂâçÂπæÁ≠ÜË≥áÊñô\n",
    "print(df.head())\n",
    "\n",
    "# È°ØÁ§∫Ê¨Ñ‰ΩçÂêçÁ®±ËàáË≥áÊñôÂûãÊÖã\n",
    "print(df.info())\n",
    "\n",
    "# Ëã•ÊÉ≥ÁúãÊ¨Ñ‰ΩçÂêçÁ®±\n",
    "print(df.columns)\n",
    "\n",
    "# È°ØÁ§∫Ë≥áÊñôÁ∂≠Â∫¶\n",
    "print(\"Ë≥áÊñôÁ∂≠Â∫¶Ôºö\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1b84b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 280\n",
      "Testing samples: 120\n",
      "Training data shape: (280, 4096)\n",
      "Testing data shape: (120, 4096)\n",
      "È°ûÂà•Êï∏ÈáèÔºö 40\n"
     ]
    }
   ],
   "source": [
    "from HW3_common_utils import load_csv_data, split_and_scale\n",
    "\n",
    "data_file = 'Data/face_data.csv'\n",
    "X, y = load_csv_data(data_file)\n",
    "X_train_, X_test_, y_train, y_test = split_and_scale(X, y, test_size=0.3)\n",
    "\n",
    "print(f\"Training samples: {X_train_.shape[0]}\")\n",
    "print(f\"Testing samples: {X_test_.shape[0]}\")\n",
    "print(f\"Training data shape: {X_train_.shape}\")\n",
    "print(f\"Testing data shape: {X_test_.shape}\")\n",
    "print(\"È°ûÂà•Êï∏ÈáèÔºö\", len(np.unique(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2d089ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 280\n",
      "Testing samples: 120\n",
      "Training data shape: (280, 4096)\n",
      "Testing data shape: (120, 4096)\n",
      "È°ûÂà•Êï∏ÈáèÔºö 40\n"
     ]
    }
   ],
   "source": [
    "data_file = 'Data/face_data.csv'\n",
    "df = pd.read_csv(data_file)\n",
    "X = np.array(df.iloc[:, :-1]) # ÊéíÈô§ÊúÄÂæå‰∏ÄÊ¨ÑÊ®ôÁ±§ N x p\n",
    "y = np.array(df.iloc[:, -1])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_ = scaler.fit_transform(X_train) # Ê®ôÊ∫ñÂåñË®ìÁ∑¥Ë≥áÊñô\n",
    "X_test_ = scaler.transform(X_test) # Ê®ôÊ∫ñÂåñÊ∏¨Ë©¶Ë≥áÊñô\n",
    "# print the numbers of training and testing samples\n",
    "print(f\"Training samples: {X_train_.shape[0]}\")\n",
    "print(f\"Testing samples: {X_test_.shape[0]}\")\n",
    "# print the shape of the data\n",
    "print(f\"Training data shape: {X_train_.shape}\")\n",
    "print(f\"Testing data shape: {X_test_.shape}\")\n",
    "print(\"È°ûÂà•Êï∏ÈáèÔºö\", len( np.unique(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d861dc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with Cross Validation and solver = lbfgs\n",
      "Best C = [69.51927962 69.51927962 69.51927962 69.51927962 69.51927962 69.51927962\n",
      " 69.51927962 69.51927962 69.51927962 69.51927962 69.51927962 69.51927962\n",
      " 69.51927962 69.51927962 69.51927962 69.51927962 69.51927962 69.51927962\n",
      " 69.51927962 69.51927962 69.51927962 69.51927962 69.51927962 69.51927962\n",
      " 69.51927962 69.51927962 69.51927962 69.51927962 69.51927962 69.51927962\n",
      " 69.51927962 69.51927962 69.51927962 69.51927962 69.51927962 69.51927962\n",
      " 69.51927962 69.51927962 69.51927962 69.51927962]\n",
      "Training score = 100.00%\n",
      "\n",
      "Testing score = 97.50%\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         3\n",
      "           2       1.00      1.00      1.00         3\n",
      "           3       1.00      1.00      1.00         3\n",
      "           4       1.00      0.67      0.80         3\n",
      "           5       0.75      1.00      0.86         3\n",
      "           6       1.00      1.00      1.00         3\n",
      "           7       0.75      1.00      0.86         3\n",
      "           8       1.00      1.00      1.00         3\n",
      "           9       1.00      0.33      0.50         3\n",
      "          10       1.00      1.00      1.00         3\n",
      "          11       1.00      1.00      1.00         3\n",
      "          12       1.00      1.00      1.00         3\n",
      "          13       1.00      1.00      1.00         3\n",
      "          14       1.00      1.00      1.00         3\n",
      "          15       1.00      1.00      1.00         3\n",
      "          16       1.00      1.00      1.00         3\n",
      "          17       1.00      1.00      1.00         3\n",
      "          18       1.00      1.00      1.00         3\n",
      "          19       1.00      1.00      1.00         3\n",
      "          20       1.00      1.00      1.00         3\n",
      "          21       1.00      1.00      1.00         3\n",
      "          22       1.00      1.00      1.00         3\n",
      "          23       1.00      1.00      1.00         3\n",
      "          24       1.00      1.00      1.00         3\n",
      "          25       1.00      1.00      1.00         3\n",
      "          26       1.00      1.00      1.00         3\n",
      "          27       1.00      1.00      1.00         3\n",
      "          28       1.00      1.00      1.00         3\n",
      "          29       1.00      1.00      1.00         3\n",
      "          30       1.00      1.00      1.00         3\n",
      "          31       1.00      1.00      1.00         3\n",
      "          32       1.00      1.00      1.00         3\n",
      "          33       1.00      1.00      1.00         3\n",
      "          34       1.00      1.00      1.00         3\n",
      "          35       1.00      1.00      1.00         3\n",
      "          36       1.00      1.00      1.00         3\n",
      "          37       1.00      1.00      1.00         3\n",
      "          38       1.00      1.00      1.00         3\n",
      "          39       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.97       120\n",
      "   macro avg       0.98      0.97      0.97       120\n",
      "weighted avg       0.98      0.97      0.97       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "opts = dict(tol = 1e-6, max_iter = int(1e6), verbose=0)\n",
    "solver = 'lbfgs'  # 'lbfgs' is the default\n",
    "# solver = 'liblinear'\n",
    "# solver = 'newton-cg'\n",
    "Cs = np.logspace(-5, 5, 20) # 20 values of C from 1e-5 to 1e5\n",
    "cv = 5 # 5-fold cross-validation\n",
    "# --- Logistic Regression with Cross Validation ---\n",
    "clf_originalCV = LogisticRegressionCV(solver = solver, Cs = Cs, cv = cv, **opts) \n",
    "clf_originalCV.fit(X_train_, y_train) # input data must be (n_samples x n_features)\n",
    "y_pred = clf_originalCV.predict(X_test_)\n",
    "\n",
    "# --- Results Report ---\n",
    "print(f\"Logistic Regression with Cross Validation and solver = {solver}\")\n",
    "# print best C value\n",
    "print(f\"Best C = {clf_originalCV.C_}\")\n",
    "# print training score\n",
    "print(f\"Training score = {accuracy_score(y_train, clf_originalCV.predict(X_train_)):.2%}\\n\")\n",
    "# print testing score\n",
    "# print(f\"Testing score = {accuracy_score(y_test, y_pred):.2%}\\n\")\n",
    "print(f\"Testing score = {clf_originalCV.score(X_test_, y_test):.2%}\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fea3361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìò Logistic Regression with CV (solver = lbfgs)\n",
      "Best C = [69.51927962 69.51927962 69.51927962 69.51927962 69.51927962 69.51927962\n",
      " 69.51927962 69.51927962 69.51927962 69.51927962 69.51927962 69.51927962\n",
      " 69.51927962 69.51927962 69.51927962 69.51927962 69.51927962 69.51927962\n",
      " 69.51927962 69.51927962 69.51927962 69.51927962 69.51927962 69.51927962\n",
      " 69.51927962 69.51927962 69.51927962 69.51927962 69.51927962 69.51927962\n",
      " 69.51927962 69.51927962 69.51927962 69.51927962 69.51927962 69.51927962\n",
      " 69.51927962 69.51927962 69.51927962 69.51927962]\n",
      "Training Accuracy: 100.00%\n",
      "Testing Accuracy : 97.50%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         3\n",
      "           2       1.00      1.00      1.00         3\n",
      "           3       1.00      1.00      1.00         3\n",
      "           4       1.00      0.67      0.80         3\n",
      "           5       0.75      1.00      0.86         3\n",
      "           6       1.00      1.00      1.00         3\n",
      "           7       0.75      1.00      0.86         3\n",
      "           8       1.00      1.00      1.00         3\n",
      "           9       1.00      0.33      0.50         3\n",
      "          10       1.00      1.00      1.00         3\n",
      "          11       1.00      1.00      1.00         3\n",
      "          12       1.00      1.00      1.00         3\n",
      "          13       1.00      1.00      1.00         3\n",
      "          14       1.00      1.00      1.00         3\n",
      "          15       1.00      1.00      1.00         3\n",
      "          16       1.00      1.00      1.00         3\n",
      "          17       1.00      1.00      1.00         3\n",
      "          18       1.00      1.00      1.00         3\n",
      "          19       1.00      1.00      1.00         3\n",
      "          20       1.00      1.00      1.00         3\n",
      "          21       1.00      1.00      1.00         3\n",
      "          22       1.00      1.00      1.00         3\n",
      "          23       1.00      1.00      1.00         3\n",
      "          24       1.00      1.00      1.00         3\n",
      "          25       1.00      1.00      1.00         3\n",
      "          26       1.00      1.00      1.00         3\n",
      "          27       1.00      1.00      1.00         3\n",
      "          28       1.00      1.00      1.00         3\n",
      "          29       1.00      1.00      1.00         3\n",
      "          30       1.00      1.00      1.00         3\n",
      "          31       1.00      1.00      1.00         3\n",
      "          32       1.00      1.00      1.00         3\n",
      "          33       1.00      1.00      1.00         3\n",
      "          34       1.00      1.00      1.00         3\n",
      "          35       1.00      1.00      1.00         3\n",
      "          36       1.00      1.00      1.00         3\n",
      "          37       1.00      1.00      1.00         3\n",
      "          38       1.00      1.00      1.00         3\n",
      "          39       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.97       120\n",
      "   macro avg       0.98      0.97      0.97       120\n",
      "weighted avg       0.98      0.97      0.97       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from HW3_common_utils import run_logistic_regression_cv\n",
    "\n",
    "# Âü∑Ë°å Logistic Regression CV\n",
    "result = run_logistic_regression_cv(\n",
    "    X_train_, X_test_, y_train, y_test,\n",
    "    solver='lbfgs',\n",
    "    Cs=np.logspace(-5, 5, 20),\n",
    "    cv=5,\n",
    "    tol=1e-6,\n",
    "    max_iter=int(1e6),\n",
    "    verbose=0,\n",
    "    print_report=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be92b1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from HW3_common_utils import apply_pca\n",
    "\n",
    "X_train_pca, X_test_pca, pca = apply_pca(X_train_, X_test_, variance_ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "837b5e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with CV (solver = lbfgs)\n",
      "Best C = [1.83298071 1.83298071 1.83298071 1.83298071 1.83298071 1.83298071\n",
      " 1.83298071 1.83298071 1.83298071 1.83298071 1.83298071 1.83298071\n",
      " 1.83298071 1.83298071 1.83298071 1.83298071 1.83298071 1.83298071\n",
      " 1.83298071 1.83298071 1.83298071 1.83298071 1.83298071 1.83298071\n",
      " 1.83298071 1.83298071 1.83298071 1.83298071 1.83298071 1.83298071\n",
      " 1.83298071 1.83298071 1.83298071 1.83298071 1.83298071 1.83298071\n",
      " 1.83298071 1.83298071 1.83298071 1.83298071]\n",
      "Training Accuracy: 100.00%\n",
      "Testing Accuracy : 96.67%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         3\n",
      "           2       1.00      1.00      1.00         3\n",
      "           3       1.00      0.67      0.80         3\n",
      "           4       1.00      0.67      0.80         3\n",
      "           5       0.75      1.00      0.86         3\n",
      "           6       1.00      1.00      1.00         3\n",
      "           7       0.60      1.00      0.75         3\n",
      "           8       1.00      1.00      1.00         3\n",
      "           9       1.00      0.33      0.50         3\n",
      "          10       1.00      1.00      1.00         3\n",
      "          11       1.00      1.00      1.00         3\n",
      "          12       1.00      1.00      1.00         3\n",
      "          13       1.00      1.00      1.00         3\n",
      "          14       1.00      1.00      1.00         3\n",
      "          15       1.00      1.00      1.00         3\n",
      "          16       1.00      1.00      1.00         3\n",
      "          17       1.00      1.00      1.00         3\n",
      "          18       1.00      1.00      1.00         3\n",
      "          19       1.00      1.00      1.00         3\n",
      "          20       1.00      1.00      1.00         3\n",
      "          21       1.00      1.00      1.00         3\n",
      "          22       1.00      1.00      1.00         3\n",
      "          23       1.00      1.00      1.00         3\n",
      "          24       1.00      1.00      1.00         3\n",
      "          25       1.00      1.00      1.00         3\n",
      "          26       1.00      1.00      1.00         3\n",
      "          27       1.00      1.00      1.00         3\n",
      "          28       1.00      1.00      1.00         3\n",
      "          29       1.00      1.00      1.00         3\n",
      "          30       1.00      1.00      1.00         3\n",
      "          31       1.00      1.00      1.00         3\n",
      "          32       1.00      1.00      1.00         3\n",
      "          33       1.00      1.00      1.00         3\n",
      "          34       1.00      1.00      1.00         3\n",
      "          35       1.00      1.00      1.00         3\n",
      "          36       1.00      1.00      1.00         3\n",
      "          37       1.00      1.00      1.00         3\n",
      "          38       1.00      1.00      1.00         3\n",
      "          39       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.97       120\n",
      "   macro avg       0.98      0.97      0.96       120\n",
      "weighted avg       0.98      0.97      0.96       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = run_logistic_regression_cv(\n",
    "    X_train_pca, X_test_pca, y_train, y_test,\n",
    "    solver='lbfgs',\n",
    "    Cs=np.logspace(-5, 5, 20),\n",
    "    cv=5,\n",
    "    tol=1e-6,\n",
    "    max_iter=int(1e6),\n",
    "    verbose=0,\n",
    "    print_report=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
